services:
  projector-backend:
    build: .
    container_name: projector_nest
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - AI_SERVICE_URL=http://ai-model:5000/generate  # URL для обращения к модели ИИ
    # volumes:
    #   - .:/app
    #   - /app/node_modules
    depends_on:
      - ai-model
    networks:
      - ai-net

  ai-model:
    image: ghcr.io/huggingface/text-generation-inference:1.1.0
    container_name: ai-model
    restart: unless-stopped
    ports:
      - "5000:5000"
    command:
      - "--model-id"
      - "tiiuae/falcon-rw-1b"
      - "--max-input-length"
      - "128"
      - "--max-total-tokens"
      - "512"
      - "--max-batch-prefill-tokens"
      - "128"
      - "--disable-custom-kernels"
      - "--port"
      - "5000"

   
    volumes:
      - ai-model-cache:/data  # Кэширование модели для ускорения последующих запусков
    runtime: nvidia
    deploy:
      resources:
        limits:
          cpus: '2'  # Ограничиваем использование CPU
          memory: 4G  # Ограничиваем память
    networks:
      - ai-net
  speech-api:
    build: ./python-services/speech-api
    container_name: speech-api
    ports:
      - "8000:8000"
    environment:
      - AI_SERVICE_URL=http://ai-model:5000/generate
    depends_on:
      - ai-model
    networks:
      - ai-net
    
volumes:
  ai-model-cache:

networks:
  ai-net: